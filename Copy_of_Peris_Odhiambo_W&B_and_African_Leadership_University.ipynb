{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MsPery/colabwork_1/blob/main/Copy_of_Peris_Odhiambo_W%26B_and_African_Leadership_University.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn2AsN_8OF9C"
      },
      "source": [
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "<!--- @wandbcode{fmnist-alu} -->\n",
        "\n",
        "Use Weights & Biases for machine learning experiment tracking, dataset versioning, and project collaboration.\n",
        "\n",
        "\n",
        "<img src=\"https://wandb.me/mini-diagram\" width=\"650\" alt=\"Weights & Biases\" />\n",
        "\n",
        "\n",
        "## What this notebook covers with Weights and Biases:\n",
        "* Using W&B to save and download your data\n",
        "* Exploratory Data Analysis (EDA)\n",
        "* Metrics logging "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNu4MLLEWoGm"
      },
      "source": [
        "# ‚úÖ Sign Up\n",
        "\n",
        "Sign up to a free [Weights & Biases account here](https://wandb.ai/signup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEjqFP8xuZ2g"
      },
      "source": [
        "[Weights and Biases docs](https://docs.wandb.ai/quickstart)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_vAHpRh9hi2"
      },
      "source": [
        "# Kaggle Competition Page\n",
        "\n",
        "[Submit to the Competition here](https://www.kaggle.com/competitions/fashion-mnist-african-leadership-university)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFmx5yiSHodB"
      },
      "source": [
        "# üöÄ Installing and importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32x5NdqZE2e1"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade wandb\n",
        "!pip install -qq timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQV_RY7nauWI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "import timm\n",
        "import wandb\n",
        "import random\n",
        "from pathlib import Path\n",
        "import torch, torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as T\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK-8urUht2VY"
      },
      "source": [
        "Set some constants "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECCOZJy_Lx5O"
      },
      "outputs": [],
      "source": [
        "PROJECT = 'fashion-mnist-alu'\n",
        "DATA_DIR = Path('data/')\n",
        "ARTIFACT_PATH = 'wandb/fashion_mnist/FashionMnist:latest'\n",
        "BS = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHlJ_rz_Izr7"
      },
      "source": [
        "# üíæ Data\n",
        "#### Download the data from W&B Artifacts\n",
        "Train, validation and test images will be downloaded, as well as train and validation labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxu2Zl3wHpcU"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=PROJECT, job_type='download_dataset')\n",
        "\n",
        "artifact = wandb.use_artifact(ARTIFACT_PATH, type='dataset')\n",
        "\n",
        "artifact_dir = artifact.download(DATA_DIR)\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaGaWjsSsm6Q"
      },
      "source": [
        "## Prepare the Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjHFFj5nkGdG"
      },
      "outputs": [],
      "source": [
        "class TensorDataset:\n",
        "    \"A simple Tensor dataset that supports transforms\"\n",
        "    def __init__(self, images, labels=None, tfms=T.ConvertImageDtype(torch.float)):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.tfms = tfms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.images[[idx]]\n",
        "        img = self.tfms(img)\n",
        "        if self.labels is not None:\n",
        "            return img, self.labels[idx].long()\n",
        "        else:\n",
        "            return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuODrsdSkGdG"
      },
      "outputs": [],
      "source": [
        "class FashionMNIST:\n",
        "    \n",
        "    tfms = {\"train\": T.Compose([T.Resize(32), T.ConvertImageDtype(torch.float)]),\n",
        "            \"valid\": T.Compose([T.Resize(32), T.ConvertImageDtype(torch.float)])}\n",
        "    \n",
        "    def __init__(self, data_dir=DATA_DIR):\n",
        "        self.ds = torch.load(data_dir/\"fashion_mnist.pt\")\n",
        "        self.train_ds = TensorDataset(self.ds[\"train\"][\"data\"], self.ds[\"train\"][\"labels\"], self.tfms[\"train\"])\n",
        "        self.valid_ds = TensorDataset(self.ds[\"valid\"][\"data\"], self.ds[\"valid\"][\"labels\"], self.tfms[\"valid\"])\n",
        "        self.test_ds = TensorDataset(self.ds[\"test\"][\"data\"], tfms=self.tfms[\"valid\"])\n",
        "    \n",
        "    def dataloaders(self, bs=128, num_workers=2):\n",
        "        train_dataloader = DataLoader(self.train_ds, batch_size=bs, shuffle=True, num_workers=num_workers)\n",
        "        valid_dataloader = DataLoader(self.valid_ds, batch_size=bs*2, shuffle=False, \n",
        "                                      num_workers=num_workers)\n",
        "        test_dataloader = DataLoader(self.test_ds, batch_size=bs*2, shuffle=False, \n",
        "                                      num_workers=num_workers)\n",
        "        return train_dataloader, valid_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uo_dd7zkGdH"
      },
      "outputs": [],
      "source": [
        "datasets = FashionMNIST(DATA_DIR)\n",
        "train_dl, valid_dl, test_dl = datasets.dataloaders(bs=BS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKYMroG_kGdH"
      },
      "source": [
        "grab one batch of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRnd74wKkGdH"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(train_dl))\n",
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV8luZPgsxpq"
      },
      "outputs": [],
      "source": [
        "def validate_model(model, valid_dl, loss_func, log_images=False, num_classes=10):\n",
        "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
        "    model.eval()\n",
        "    val_loss = 0.\n",
        "    with torch.inference_mode():\n",
        "        correct = 0\n",
        "        for i, (images, labels) in enumerate(valid_dl):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass ‚û°\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_func(outputs, labels)*labels.size(0)\n",
        "\n",
        "            # Compute accuracy and accumulate\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Log validation predictions and images to the dashboard\n",
        "            if log_images:\n",
        "              if i ==0:\n",
        "                # üêù Create a wandb Table to log images, labels and predictions to\n",
        "                table = wandb.Table(columns=[\"image\", \"label\", \"pred\"]+[f\"score_{i}\" for i in range(num_classes)])\n",
        "              \n",
        "              probs = outputs.softmax(dim=1)\n",
        "              for img, label, pred, prob in zip(images.to(\"cpu\"), labels.to(\"cpu\"), predicted.to(\"cpu\"),  probs.to(\"cpu\")):\n",
        "                  # table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
        "                  table.add_data(wandb.Image(img[0].numpy()), label, pred, *prob.numpy())\n",
        "        \n",
        "        if log_images:\n",
        "          wandb.log({\"val_table/predictions_table\":table}, commit=False)\n",
        "\n",
        "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v6_lwPtYPSd"
      },
      "source": [
        "Initialise the Datasets and Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0QTt8NxxOBd"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QitMqcHzRjTr"
      },
      "outputs": [],
      "source": [
        "len(train_dl), len(valid_dl), len(test_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ni9t9sfArq"
      },
      "source": [
        "# üëü Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgppQ0msCglo"
      },
      "outputs": [],
      "source": [
        "LR = 1e-3\n",
        "EPOCHS = 10\n",
        "\n",
        "# Log the final results on the validation set\n",
        "LOG_IMAGES=True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqWMZCd1xfIJ"
      },
      "source": [
        "Get Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f6TJigHwcke"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'resnet10t'\n",
        "\n",
        "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=10, in_chans=1)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIU3VCweTvSX"
      },
      "source": [
        "üêù initialise a wandb run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSvGEtymTtMB"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=PROJECT, config={\"epochs\": EPOCHS, \"batch_size\": BS, \"lr\": LR})\n",
        "\n",
        "# Add additional configs to wandb if needed\n",
        "wandb.config['len_train'] = len(datasets.train_ds)\n",
        "wandb.config['len_val'] = len(datasets.valid_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLS60o7FDk6L"
      },
      "source": [
        "Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqD2_42JxFwO",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copy your config \n",
        "config = wandb.config\n",
        "\n",
        "# Get the data\n",
        "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
        "\n",
        "# Make the loss and optimizer\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
        "\n",
        "# Training\n",
        "example_ct = 1\n",
        "step_ct = 1\n",
        "for epoch in tqdm(range(config.epochs)):\n",
        "    model.train()\n",
        "    for step, (images, labels) in enumerate(tqdm(train_dl, leave=False)):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        train_loss = loss_func(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        example_ct += len(images)\n",
        "        metrics = {\"train/train_loss\": train_loss, \n",
        "                    \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch, \n",
        "                    \"train/example_ct\": example_ct}\n",
        "        \n",
        "        if step + 1 < n_steps_per_epoch:\n",
        "            # üêù Log train metrics to wandb \n",
        "            wandb.log(metrics)\n",
        "            \n",
        "        step_ct += 1\n",
        "    \n",
        "    # log validation images and predictions on last epoch\n",
        "    if LOG_IMAGES:\n",
        "        log_images = epoch==(config.epochs-1)\n",
        "    else:\n",
        "        log_images = False\n",
        "\n",
        "    # Do validation and maybe log images to Tables\n",
        "    val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=log_images)\n",
        "\n",
        "    # üêù Log train and validation metrics to wandb\n",
        "    val_metrics = {\"val/val_loss\": val_loss, \n",
        "                    \"val/val_accuracy\": accuracy}\n",
        "    wandb.log({**metrics, **val_metrics})\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:.3f}, Valid Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save trained model to disk and to W&B Artifacts\n",
        "model_fn = f'{MODEL_NAME}_model.pt'\n",
        "torch.save(model, model_fn)\n",
        "wandb.log_artifact(model_fn, f'{MODEL_NAME}_model', type='model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DesBwID32HJ"
      },
      "source": [
        "# Generate Test Submission\n",
        "Generate Test Predictions and Log Submission File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjo2pIZcRMKA"
      },
      "outputs": [],
      "source": [
        "preds = []\n",
        "for step, images in enumerate(tqdm(test_dl, leave=False)):\n",
        "    images = images.to(device)\n",
        "    outputs = model(images)\n",
        "    preds.append(outputs.argmax(1).cpu().numpy().tolist())\n",
        "\n",
        "preds = [p for ps in preds for p in ps]\n",
        "len(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ9mZZyCUDtL"
      },
      "outputs": [],
      "source": [
        "submission_df = pd.DataFrame({'Id':list(range(len(preds))), 'Category':preds})\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEwjSJqjUMeF"
      },
      "source": [
        "Log your submission file to your wandb run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu0Lu92KTYqf"
      },
      "outputs": [],
      "source": [
        "wandb.log_artifact('submission.csv', 'submission_file', type='submission')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C03T4ecUK-H"
      },
      "source": [
        "üêù Close your wandb run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIHtZ-QEuVV8"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A4CVu1L1zN0"
      },
      "source": [
        "# ü™Ñ More from W&B\n",
        "\n",
        "#### üìè Best Practices\n",
        "\n",
        "1. **Projects**: Log multiple runs to a project to compare them. `wandb.init(project=\"project-name\")`\n",
        "2. **Groups**: For multiple processes or cross validation folds, log each process as a run and group them together. `wandb.init(group='experiment-1')`\n",
        "3. **Tags**: Add tags to track your current baseline or production model.\n",
        "4. **Notes**: Type notes in the table to track the changes between runs.\n",
        "5. **Reports**: Take quick notes on progress to share with colleagues and make dashboards and snapshots of your ML projects.\n",
        "\n",
        "# What's next üöÄ ?\n",
        "The next tutorial you will learn how to do hyperparameter optimization using W&B Sweeps:\n",
        "## üëâ [Hyperparameters sweeps using PyTorch](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}